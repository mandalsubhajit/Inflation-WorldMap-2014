localH2O <- h2o.init(nthread=4,Xmx="24g")
localH2O <- h2o.init(nthread=4,Xmx="24g")
library(mefa)
library(lubridate)
install.packages(c("mefa", "lubridate"))
path <- "D:/Google Drive/Kaggle/West Nile Virus Prediction/input/"
train = read.csv(paste0(path,"train.csv"),header=TRUE,stringsAsFactors = T)
test = read.csv(paste0(path,"test.csv"),header=TRUE,stringsAsFactors = T)
weather = read.csv(paste0(path,"weather.csv"),header=TRUE,stringsAsFactors = T)
spray = read.csv(paste0(path,"spray.csv"),header=TRUE)
subm = read.csv(paste0(path,"sampleSubmission.csv"),header=TRUE,stringsAsFactors = F)
subm = read.csv(paste0(path,"sampleSubmission.csv"),header=TRUE,stringsAsFactors = F)
weather[(weather == " ")] <- NA
weather[(weather == "M")] <- NA
weather[(weather == "-")] <- NA
weather[(weather == "T")] <- NA
weather[(weather == " T")] <- NA
weather[(weather == "  T")] <- NA
weather[(weather == " ")] <- NA
weather[(weather == "M")] <- NA
weather[(weather == "-")] <- NA
weather[(weather == "T")] <- NA
weather[(weather == " T")] <- NA
weather[(weather == "  T")] <- NA
train$Station <- ifelse((((train$Latitude-41.995)^2 + (train$Longitude + 87.933)^2) <
((train$Latitude-41.786)^2 + (train$Longitude + 87.752)^2)),1,2)
test$Station <- ifelse((((test$Latitude-41.995)^2 + (test$Longitude + 87.933)^2) <
((test$Latitude-41.786)^2 + (test$Longitude + 87.752)^2)),1,2)
w1 = weather[weather$Station ==1,]
w2 = weather[weather$Station ==2,]
#Replace NA's with the nearest value above
W1 <- rbind(w1[2,],w1)
W1 <- fill.na(W1)
W1 <- W1[-1,]
rownames(W1) <- NULL
W2 <- rbind(w2[2,],w2)
W2 <- fill.na(W2)
W2 <- W2[-1,]
rownames(W2) <- NULL
Weather <- rbind(W1,W2)
for(i in c(3:9,11:16)){
Weather[,i] <- as.numeric(Weather[,i])
}
Weather[,10] <- factor(Weather[,10])
train <- merge.data.frame(train,Weather)
test <- merge.data.frame(test,Weather)
test <- test[with(test,order(Id)),]
train$day<-as.numeric(day(as.Date(train$Date)))
train$dayofyear<-as.numeric(yday(as.Date(train$Date)))
#train$month<-factor(month(as.Date(train$Date)))
train$dayofweek<-as.factor(wday(as.Date(train$Date)))
train$year <- as.factor(year(as.Date(train$Date)))
train$week <- as.integer(week(as.Date(train$Date)))
library(mefa)
library(lubridate)
library(mefa)
library(lubridate)
path <- "D:/Google Drive/Kaggle/West Nile Virus Prediction/input/"
train = read.csv(paste0(path,"train.csv"),header=TRUE,stringsAsFactors = T)
test = read.csv(paste0(path,"test.csv"),header=TRUE,stringsAsFactors = T)
weather = read.csv(paste0(path,"weather.csv"),header=TRUE,stringsAsFactors = T)
spray = read.csv(paste0(path,"spray.csv"),header=TRUE)
subm = read.csv(paste0(path,"sampleSubmission.csv"),header=TRUE,stringsAsFactors = F)
weather[(weather == " ")] <- NA
weather[(weather == "M")] <- NA
weather[(weather == "-")] <- NA
weather[(weather == "T")] <- NA
weather[(weather == " T")] <- NA
weather[(weather == "  T")] <- NA
weather$Water1 = NULL
weather$Depth = NULL
weather$SnowFall = NULL
weather$Sunrise = NULL
weather$Sunset = NULL
weather$Depart = NULL
#Get the nearest station
train$Station <- ifelse((((train$Latitude-41.995)^2 + (train$Longitude + 87.933)^2) <
((train$Latitude-41.786)^2 + (train$Longitude + 87.752)^2)),1,2)
test$Station <- ifelse((((test$Latitude-41.995)^2 + (test$Longitude + 87.933)^2) <
((test$Latitude-41.786)^2 + (test$Longitude + 87.752)^2)),1,2)
w1 = weather[weather$Station ==1,]
w2 = weather[weather$Station ==2,]
#Replace NA's with the nearest value above
W1 <- rbind(w1[2,],w1)
W1 <- fill.na(W1)
W1 <- W1[-1,]
rownames(W1) <- NULL
W2 <- rbind(w2[2,],w2)
W2 <- fill.na(W2)
W2 <- W2[-1,]
rownames(W2) <- NULL
Weather <- rbind(W1,W2)
for(i in c(3:9,11:16)){
Weather[,i] <- as.numeric(Weather[,i])
}
Weather[,10] <- factor(Weather[,10])
train <- merge.data.frame(train,Weather)
test <- merge.data.frame(test,Weather)
test <- test[with(test,order(Id)),]
train$day<-as.numeric(day(as.Date(train$Date)))
train$dayofyear<-as.numeric(yday(as.Date(train$Date)))
#train$month<-factor(month(as.Date(train$Date)))
train$dayofweek<-as.factor(wday(as.Date(train$Date)))
train$year <- as.factor(year(as.Date(train$Date)))
train$week <- as.integer(week(as.Date(train$Date)))
test$day<-as.numeric(day(as.Date(test$Date)))
test$dayofyear<-as.numeric(yday(as.Date(test$Date)))
#test$month<-factor(month(as.Date(test$Date)))
test$dayofweek<-as.factor(wday(as.Date(test$Date)))
test$year <- as.factor(year(as.Date(test$Date)))
test$week <- as.integer(week(as.Date(test$Date)))
library(h2o)
localH2O <- h2o.init(nthreads = -1,max_mem_size = '7g')
test.hex <- as.h2o(localH2O,test)
train.hex <- as.h2o(localH2O,train)
model <- h2o.randomForest(x=c(4:11,14:32),y = 13,data = train.hex,
mtries = 18,
sample.rate = 0.5,
classification = T,ntree = 500,verbose = T)
model
pred <- h2o.predict(model,test.hex)
p <- as.data.frame(pred)
summary(p)
subm[,2] = p[,3]
summary(subm)
write.csv(subm,file=paste0(path,"output/H2ORF.csv"),row.names=FALSE)
write.csv(subm,file=paste0(path,"../output/H2ORF.csv"),row.names=FALSE)
install.packages("caret")
require(caret)
?dummyVars
when <- data.frame(time = c("afternoon", "night", "afternoon",
"morning", "morning", "morning",
"morning", "afternoon", "afternoon"),
day = c("Mon", "Mon", "Mon",
"Wed", "Wed", "Fri",
"Sat", "Sat", "Fri"))
levels(when$time) <- list(morning="morning",
afternoon="afternoon",
night="night")
levels(when$day) <- list(Mon="Mon", Tue="Tue", Wed="Wed", Thu="Thu",
Fri="Fri", Sat="Sat", Sun="Sun")
model.matrix(~day, when)
mainEffects <- dummyVars(~ day + time, data = when)
mainEffects
predict(mainEffects, when[1:3,])
model.matrix(~day+time, when)
when
# install.packages("devtools")
# library("devtools")
# install_github("Ram-N/weatherData")
library(weatherData)
dat <- getWeatherForDate("PHNL", "2013-08-10", "2013-08-31")
dat <- getWeatherForDate("VOHY", "2013-08-10", "2013-08-31")
dat <- getWeatherForDate("VOHY", "2005-08-10", "2005-08-31")
View(dat)
dat <- getWeatherForDate("VOHY", "2009-08-10", "2009-08-31")
View(dat)
dat <- getWeatherForDate("VOHY", "2005-08-10", "2005-08-31")
View(dat)
dat <- getWeatherForDate("VOHY", "2009-08-10", "2009-08-31")
stn <- getStationCode("Ceeldheer")
stn <- getStationCode("ceeldheer")
stn <- getStationCode("hyderabad")
stn
USAirportWeatherStations
head(USAirportWeatherStations)
USAirportWeatherStations[(Lat>0)&(Lat<5)&(Lon>46)&(Lon<50),]
USAirportWeatherStations[(USAirportWeatherStations$Lat>0)&(USAirportWeatherStations$Lat<5)&(USAirportWeatherStations$Lon>46)&(USAirportWeatherStations$Lon<50),]
USAirportWeatherStations[(USAirportWeatherStations$airportCode=="VOHY"),]
doInstall <- TRUE
toInstall <- c("twitteR", "dismo", "maps", "ggplot2")
if(doInstall){install.packages(toInstall, repos = "http://cran.us.r-project.org")}
lapply(toInstall, library, character.only = TRUE)
searchTerm <- "#rstats"
searchResults <- searchTwitter(searchTerm, n = 1000)  # Gather Tweets
library(twitteR)
library(ROAuth)
library(plyr)
library(dplyr)
library(stringr)
library(ggplot2)
download.file(url='http://curl.haxx.se/ca/cacert.pem', destfile='cacert.pem')
reqURL <- 'https://api.twitter.com/oauth/request_token'
accessURL <- 'https://api.twitter.com/oauth/access_token'
authURL <- 'https://api.twitter.com/oauth/authorize'
consumerKey <- 'n2oVI9TwN3mBRleKuBqZRYW3o' #put the Consumer Key from Twitter Application
consumerSecret <- 'DngSiIG3CdAHd6e5KGoLIhamy18AoIzPHHaFnzfEev7bHPxXNe'  #put the Consumer Secret from Twitter Application
Cred <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=reqURL,
accessURL=accessURL,
authURL=authURL)
Cred$handshake(cainfo = system.file('CurlSSL', 'cacert.pem', package = 'RCurl')) #There is URL in Console. You need to go to it, get code and enter it on Console
registerTwitterOAuth(Cred)
Cred$handshake(cainfo = system.file('CurlSSL', 'cacert.pem', package = 'RCurl')) #There is URL in Console. You need to go to it, get code and enter it on Console
registerTwitterOAuth(Cred)
#the function of tweets accessing and analyzing
search <- function(searchterm)
{
#access tweets and create cumulative file
list <- searchTwitter(searchterm, cainfo='cacert.pem', n=1500)
df <- twListToDF(list)
df <- df[, order(names(df))]
df$created <- strftime(df$created, '%Y-%m-%d')
if (file.exists(paste(searchterm, '_stack.csv'))==FALSE) write.csv(df, file=paste(searchterm, '_stack.csv'), row.names=F)
#merge last access with cumulative file and remove duplicates
stack <- read.csv(file=paste(searchterm, '_stack.csv'))
stack <- rbind(stack, df)
stack <- subset(stack, !duplicated(stack$text))
write.csv(stack, file=paste(searchterm, '_stack.csv'), row.names=F)
#evaluation tweets function
score.sentiment <- function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
scores <- laply(sentences, function(sentence, pos.words, neg.words){
sentence <- gsub('[[:punct:]]', "", sentence)
sentence <- gsub('[[:cntrl:]]', "", sentence)
sentence <- gsub('\d+', "", sentence)
sentence <- tolower(sentence)
word.list <- str_split(sentence, '\s+')
words <- unlist(word.list)
pos.matches <- match(words, pos.words)
neg.matches <- match(words, neg.words)
pos.matches <- !is.na(pos.matches)
neg.matches <- !is.na(neg.matches)
score <- sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress)
scores.df <- data.frame(score=scores, text=sentences)
return(scores.df)
}
pos <- scan('C:/___________/positive-words.txt', what='character', comment.char=';') #folder with positive dictionary
neg <- scan('C:/___________/negative-words.txt', what='character', comment.char=';') #folder with negative dictionary
pos.words <- c(pos, 'upgrade')
neg.words <- c(neg, 'wtf', 'wait', 'waiting', 'epicfail')
Dataset <- stack
Dataset$text <- as.factor(Dataset$text)
scores <- score.sentiment(Dataset$text, pos.words, neg.words, .progress='text')
write.csv(scores, file=paste(searchterm, '_scores.csv'), row.names=TRUE) #save evaluation results into the file
#total evaluation: positive / negative / neutral
stat <- scores
stat$created <- stack$created
stat$created <- as.Date(stat$created)
stat <- mutate(stat, tweet=ifelse(stat$score > 0, 'positive', ifelse(stat$score < 0, 'negative', 'neutral')))
by.tweet <- group_by(stat, tweet, created)
by.tweet <- summarise(by.tweet, number=n())
write.csv(by.tweet, file=paste(searchterm, '_opin.csv'), row.names=TRUE)
#create chart
ggplot(by.tweet, aes(created, number)) + geom_line(aes(group=tweet, color=tweet), size=2) +
geom_point(aes(group=tweet, color=tweet), size=4) +
theme(text = element_text(size=18), axis.text.x = element_text(angle=90, vjust=1)) +
#stat_summary(fun.y = 'sum', fun.ymin='sum', fun.ymax='sum', colour = 'yellow', size=2, geom = 'line') +
ggtitle(searchterm)
ggsave(file=paste(searchterm, '_plot.jpeg'))
}
searchTwitter('apartment hunting', geocode='40.7361,-73.9901,5mi',  n=5000, retryOnRateLimit=1)
registerTwitterOAuth(Cred)
api_key = "n2oVI9TwN3mBRleKuBqZRYW3o" // your api_key
api_secret = "DngSiIG3CdAHd6e5KGoLIhamy18AoIzPHHaFnzfEev7bHPxXNe" // your api_secret
access_token = "105196636-B0SoC0gfx7sgcXR9JfqyiMydn0TttV7kppTbIfYt" // your access_token
access_token_secret = "3RvVmv9cmaFE1kC7EmcdzXusQ6R9BjvHEi9PmLFmMsOlG" // your access_token_sceret
setup_twitter_oauth(api_key,api_secret,access_token,
access_token_secret)
api_key = "n2oVI9TwN3mBRleKuBqZRYW3o" # your api_key
api_secret = "DngSiIG3CdAHd6e5KGoLIhamy18AoIzPHHaFnzfEev7bHPxXNe" # your api_secret
access_token = "105196636-B0SoC0gfx7sgcXR9JfqyiMydn0TttV7kppTbIfYt" # your access_token
access_token_secret = "3RvVmv9cmaFE1kC7EmcdzXusQ6R9BjvHEi9PmLFmMsOlG" # your access_token_sceret
setup_twitter_oauth(api_key,api_secret,access_token,
access_token_secret)
api_key = "n2oVI9TwN3mBRleKuBqZRYW3o" # your api_key
api_secret = "DngSiIG3CdAHd6e5KGoLIhamy18AoIzPHHaFnzfEev7bHPxXNe" # your api_secret
access_token = "105196636-B0SoC0gfx7sgcXR9JfqyiMydn0TttV7kppTbIfYt" # your access_token
access_token_secret = "3RvVmv9cmaFE1kC7EmcdzXusQ6R9BjvHEi9PmLFmMsOlG" # your access_token_sceret
setup_twitter_oauth(api_key,api_secret,access_token,
access_token_secret)
api_key = "n2oVI9TwN3mBRleKuBqZRYW3o" # your api_key
api_secret = "DngSiIG3CdAHd6e5KGoLIhamy18AoIzPHHaFnzfEev7bHPxXNe" # your api_secret
access_token = "105196636-B0SoC0gfx7sgcXR9JfqyiMydn0TttV7kppTbIfYt" # your access_token
access_token_secret = "3RvVmv9cmaFE1kC7EmcdzXusQ6R9BjvHEi9PmLFmMsOlG" # your access_token_sceret
setup_twitter_oauth(api_key,api_secret,access_token,
access_token_secret)
api_key = "n2oVI9TwN3mBRleKuBqZRYW3o" # your api_key
api_secret = "DngSiIG3CdAHd6e5KGoLIhamy18AoIzPHHaFnzfEev7bHPxXNe" # your api_secret
access_token = "105196636-B0SoC0gfx7sgcXR9JfqyiMydn0TttV7kppTbIfYt" # your access_token
access_token_secret = "3RvVmv9cmaFE1kC7EmcdzXusQ6R9BjvHEi9PmLFmMsOlG" # your access_token_sceret
setup_twitter_oauth(api_key,api_secret,access_token,
access_token_secret)
library(twitteR)
setup_twitter_oauth(api_key,api_secret,access_token,
access_token_secret)
setup_twitter_oauth(api_key,api_secret,access_token,
access_token_secret)
library(twitteR)
api_key = "n2oVI9TwN3mBRleKuBqZRYW3o" # your api_key
api_secret = "DngSiIG3CdAHd6e5KGoLIhamy18AoIzPHHaFnzfEev7bHPxXNe" # your api_secret
access_token = "105196636-B0SoC0gfx7sgcXR9JfqyiMydn0TttV7kppTbIfYt" # your access_token
access_token_secret = "3RvVmv9cmaFE1kC7EmcdzXusQ6R9BjvHEi9PmLFmMsOlG" # your access_token_sceret
setup_twitter_oauth(api_key,api_secret,access_token,
access_token_secret)
library(twitteR)
api_key = "n2oVI9TwN3mBRleKuBqZRYW3o" # your api_key
api_secret = "DngSiIG3CdAHd6e5KGoLIhamy18AoIzPHHaFnzfEev7bHPxXNe" # your api_secret
access_token = "105196636-B0SoC0gfx7sgcXR9JfqyiMydn0TttV7kppTbIfYt" # your access_token
access_token_secret = "3RvVmv9cmaFE1kC7EmcdzXusQ6R9BjvHEi9PmLFmMsOlG" # your access_token_sceret
setup_twitter_oauth(consumer_key=api_key,consumer_secret=api_secret,access_token=access_token,
access_secret=access_token_secret)
library(devtools)
install_github("twitteR", username="geoffjentry")
library(twitteR)
api_key = "n2oVI9TwN3mBRleKuBqZRYW3o" # your api_key
api_secret = "DngSiIG3CdAHd6e5KGoLIhamy18AoIzPHHaFnzfEev7bHPxXNe" # your api_secret
access_token = "105196636-B0SoC0gfx7sgcXR9JfqyiMydn0TttV7kppTbIfYt" # your access_token
access_token_secret = "3RvVmv9cmaFE1kC7EmcdzXusQ6R9BjvHEi9PmLFmMsOlG" # your access_token_sceret
setup_twitter_oauth(consumer_key=api_key,consumer_secret=api_secret,access_token=access_token,
access_secret=access_token_secret)
library(devtools)
install_github("twitteR", username="geoffjentry")
library(twitteR)
api_key = "n2oVI9TwN3mBRleKuBqZRYW3o" # your api_key
api_secret = "DngSiIG3CdAHd6e5KGoLIhamy18AoIzPHHaFnzfEev7bHPxXNe" # your api_secret
access_token = "105196636-B0SoC0gfx7sgcXR9JfqyiMydn0TttV7kppTbIfYt" # your access_token
access_token_secret = "3RvVmv9cmaFE1kC7EmcdzXusQ6R9BjvHEi9PmLFmMsOlG" # your access_token_sceret
setup_twitter_oauth(consumer_key=api_key,consumer_secret=api_secret,access_token=access_token,
access_secret=access_token_secret)
install(base64enc)
install("base64enc")
install.packages("base64enc")
library(base64enc)
library(twitteR)
api_key = "n2oVI9TwN3mBRleKuBqZRYW3o" # your api_key
api_secret = "DngSiIG3CdAHd6e5KGoLIhamy18AoIzPHHaFnzfEev7bHPxXNe" # your api_secret
access_token = "105196636-B0SoC0gfx7sgcXR9JfqyiMydn0TttV7kppTbIfYt" # your access_token
access_token_secret = "3RvVmv9cmaFE1kC7EmcdzXusQ6R9BjvHEi9PmLFmMsOlG" # your access_token_sceret
setup_twitter_oauth(consumer_key=api_key,consumer_secret=api_secret,access_token=access_token,
access_secret=access_token_secret)
searchTwitter('apartment hunting', geocode='40.7361,-73.9901,5mi',  n=5000, retryOnRateLimit=1)
searchTwitter('KFC', geocode='40.7361,-73.9901,5mi',  n=5000, retryOnRateLimit=1)
searchTwitter('modi',  n=5000, retryOnRateLimit=1)
searchTwitter('modi',  n=25, retryOnRateLimit=1)
searchTwitter('modi',  n=5000, since='2016-01-01', until='2016-01-02', retryOnRateLimit=1)
searchTwitter('modi',  n=25, since='2016-01-01', until='2016-01-02', retryOnRateLimit=1)
install.packages(rworldmap)
install.packages('rworldmap')
library(rworldmap)
theCountries <- c("DEU", "COD", "BFA")
# These are the ISO3 names of the countries you'd like to plot in red
malDF <- data.frame(country = c("DEU", "COD", "BFA"),
malaria = c(1, 1, 1))
# malDF is a data.frame with the ISO3 country names plus a variable to
malMap <- joinCountryData2Map(malDF, joinCode = "ISO3",
nameJoinColumn = "country")
# This will join your malDF data.frame to the country map data
mapCountryData(malMap, nameColumnToPlot="malaria", catMethod = "categorical",
missingCountryCol = gray(.8))
library(qdap)
polarity("love")
polarity("hate")
#library(devtools)
#install_github("twitteR", username="geoffjentry")
#install.packages("base64enc")
library(base64enc) # authorization does not work without loading this library
library(twitteR)
api_key = "HM7PBzTTcQY6k36yhrccOxBiS" # your api_key
api_secret = "DHDVu636euKZnd0JjSeMPjjTbP0k3j2pY4zB10W3Ekg5uySZ5s" # your api_secret
access_token = "105196636-tABXuLrDn0LFjIx3PfwRV3PvqUfoGSI1A11HGc0a" # your access_token
access_token_secret = "UHMVrdI05EWyJfQzS3o2c6Uv4yeahJFpGJ3nE6pJsjNZL" # your access_token_sceret
setup_twitter_oauth(consumer_key=api_key, consumer_secret=api_secret, access_token=access_token, access_secret=access_token_secret)
searchTwitter('starwars',  n=25, since='2016-01-01', until='2016-01-02', retryOnRateLimit=1)
library(rworldmap)
data(countryExData)
sPDF <- joinCountryData2Map( countryExData
,joinCode = "ISO3"
,nameJoinColumn = "ISO3V10")
mapDevice() #create world map shaped window
mapCountryData(sPDF
,nameColumnToPlot='BIODIVERSITY')
library(rworldmap)
setwd("D:\\Github\\Inflation WorldMap 2014")
inflationData <- read.csv("data.csv")
inflDF <- joinCountryData2Map( inflationData
,joinCode = "ISO3"
,nameJoinColumn = "Country.Code")
mapDevice() #create world map shaped window
mapCountryData(inflDF
,nameColumnToPlot='Inflation')
?mapCountryData
library(rworldmap)
setwd("D:\\Github\\Inflation WorldMap 2014")
inflationData <- read.csv("data.csv")
inflDF <- joinCountryData2Map( inflationData
,joinCode = "ISO3"
,nameJoinColumn = "Country.Code")
mapDevice() #create world map shaped window
mapParams <- mapCountryData(inflDF
,nameColumnToPlot='Inflation')
do.call( addMapLegend, c( mapParams
, legendLabels="all"
, legendWidth=0.5
))
do.call( addMapLegend, c( mapParams
, legendLabels="all"
, legendWidth=0.25
))
library(rworldmap)
setwd("D:\\Github\\Inflation WorldMap 2014")
inflationData <- read.csv("data.csv")
inflDF <- joinCountryData2Map( inflationData
,joinCode = "ISO3"
,nameJoinColumn = "Country.Code")
mapDevice() #create world map shaped window
mapParams <- mapCountryData(inflDF
,nameColumnToPlot='Inflation')
do.call( addMapLegend, c( mapParams
, legendLabels="all"
, legendWidth=0.5
))
library(rworldmap)
setwd("D:\\Github\\Inflation WorldMap 2014")
inflationData <- read.csv("data.csv")
inflDF <- joinCountryData2Map( inflationData
,joinCode = "ISO3"
,nameJoinColumn = "Country.Code")
mapDevice() #create world map shaped window
mapParams <- mapCountryData(inflDF
,nameColumnToPlot='Inflation'
, addLegend='FALSE')
do.call( addMapLegend, c( mapParams
, legendLabels="all"
, legendWidth=0.5
))
library(rworldmap)
setwd("D:\\Github\\Inflation WorldMap 2014")
inflationData <- read.csv("data.csv")
inflDF <- joinCountryData2Map( inflationData
,joinCode = "ISO3"
,nameJoinColumn = "Country.Code")
mapDevice() #create world map shaped window
mapParams <- mapCountryData(inflDF
,nameColumnToPlot='Inflation'
, addLegend='FALSE'
, mapTitle = 'Inflation across Countries')
do.call( addMapLegend, c( mapParams
, legendLabels="all"
, legendWidth=0.5
))
library(rworldmap)
setwd("D:\\Github\\Inflation WorldMap 2014")
inflationData <- read.csv("data.csv")
inflDF <- joinCountryData2Map( inflationData
,joinCode = "ISO3"
,nameJoinColumn = "Country.Code")
mapDevice() #create world map shaped window
mapParams <- mapCountryData(inflDF
,nameColumnToPlot='Inflation'
, addLegend='FALSE'
, mapTitle = 'Inflation across Countries')
do.call( addMapLegend, c( mapParams
, legendLabels="all"
, legendWidth=0.5
))
library(rworldmap)
setwd("D:\\Github\\Inflation WorldMap 2014")
inflationData <- read.csv("data.csv")
inflDF <- joinCountryData2Map( inflationData
,joinCode = "ISO3"
,nameJoinColumn = "Country.Code")
mapDevice("WorldMap.png") #create world map shaped window
mapParams <- mapCountryData(inflDF
,nameColumnToPlot='Inflation'
, addLegend='FALSE'
, mapTitle = 'Inflation across Countries')
do.call( addMapLegend, c( mapParams
, legendLabels="all"
, legendWidth=0.5
))
dev.off()
library(rworldmap)
setwd("D:\\Github\\Inflation WorldMap 2014")
inflationData <- read.csv("data.csv")
inflDF <- joinCountryData2Map( inflationData
,joinCode = "ISO3"
,nameJoinColumn = "Country.Code")
png("WorldMap.png")
mapDevice() #create world map shaped window
mapParams <- mapCountryData(inflDF
,nameColumnToPlot='Inflation'
, addLegend='FALSE'
, mapTitle = 'Inflation across Countries')
do.call( addMapLegend, c( mapParams
, legendLabels="all"
, legendWidth=0.5
))
dev.off()
dev.off()
?mapDevice
library(rworldmap)
setwd("D:\\Github\\Inflation WorldMap 2014")
inflationData <- read.csv("data.csv")
inflDF <- joinCountryData2Map( inflationData
,joinCode = "ISO3"
,nameJoinColumn = "Country.Code")
mapDevice(device = "png") #create world map shaped window
mapParams <- mapCountryData(inflDF
,nameColumnToPlot='Inflation'
, addLegend='FALSE'
, mapTitle = 'Inflation across Countries')
do.call( addMapLegend, c( mapParams
, legendLabels="all"
, legendWidth=0.5
))
dev.off()
